{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note id</th>\n",
       "      <th>person id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender source value</th>\n",
       "      <th>BMI</th>\n",
       "      <th>admission department</th>\n",
       "      <th>division</th>\n",
       "      <th>ward</th>\n",
       "      <th>asa class</th>\n",
       "      <th>surgeon id</th>\n",
       "      <th>...</th>\n",
       "      <th>condition source value</th>\n",
       "      <th>surgery room</th>\n",
       "      <th>previous surgery</th>\n",
       "      <th>emergency status</th>\n",
       "      <th>op timing</th>\n",
       "      <th>day of the week</th>\n",
       "      <th>week of the month</th>\n",
       "      <th>month</th>\n",
       "      <th>surgeon estimated op time</th>\n",
       "      <th>surgery duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101058</td>\n",
       "      <td>29</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>25.247087</td>\n",
       "      <td>General Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>NUGW2</td>\n",
       "      <td>2</td>\n",
       "      <td>9885</td>\n",
       "      <td>...</td>\n",
       "      <td>D00002196</td>\n",
       "      <td>203</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>TF2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4th</td>\n",
       "      <td>October</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57801</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>24.376249</td>\n",
       "      <td>Otolaryngology</td>\n",
       "      <td>Admission</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>6194</td>\n",
       "      <td>...</td>\n",
       "      <td>D00003798</td>\n",
       "      <td>504</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2nd</td>\n",
       "      <td>January</td>\n",
       "      <td>300</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71288</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>24.376249</td>\n",
       "      <td>Otolaryngology</td>\n",
       "      <td>Admission</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>6194</td>\n",
       "      <td>...</td>\n",
       "      <td>D00003798</td>\n",
       "      <td>504</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>TF4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4th</td>\n",
       "      <td>April</td>\n",
       "      <td>100</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135104</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>24.376249</td>\n",
       "      <td>Otolaryngology</td>\n",
       "      <td>Admission</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>6194</td>\n",
       "      <td>...</td>\n",
       "      <td>D00003798</td>\n",
       "      <td>504</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>TF2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3rd</td>\n",
       "      <td>August</td>\n",
       "      <td>100</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221210</td>\n",
       "      <td>71</td>\n",
       "      <td>94</td>\n",
       "      <td>M</td>\n",
       "      <td>27.963140</td>\n",
       "      <td>Orthopedics</td>\n",
       "      <td>Admission</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>29473</td>\n",
       "      <td>...</td>\n",
       "      <td>D00018711</td>\n",
       "      <td>108</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>TF4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>5th</td>\n",
       "      <td>March</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161214</th>\n",
       "      <td>297111</td>\n",
       "      <td>4055249</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>23.700428</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>1</td>\n",
       "      <td>100613</td>\n",
       "      <td>...</td>\n",
       "      <td>D00011688</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>etc</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2nd</td>\n",
       "      <td>September</td>\n",
       "      <td>200</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161215</th>\n",
       "      <td>297455</td>\n",
       "      <td>4055328</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>20.612160</td>\n",
       "      <td>Pediatric Urology</td>\n",
       "      <td>Day</td>\n",
       "      <td>PDSC</td>\n",
       "      <td>1</td>\n",
       "      <td>6259</td>\n",
       "      <td>...</td>\n",
       "      <td>D00016707</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4th</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161216</th>\n",
       "      <td>297761</td>\n",
       "      <td>4055407</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>12.502703</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>2</td>\n",
       "      <td>105057</td>\n",
       "      <td>...</td>\n",
       "      <td>D00011524</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3rd</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161217</th>\n",
       "      <td>297753</td>\n",
       "      <td>4055558</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>14.365794</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>2</td>\n",
       "      <td>105057</td>\n",
       "      <td>...</td>\n",
       "      <td>D00004831</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>TF6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3rd</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161218</th>\n",
       "      <td>298112</td>\n",
       "      <td>4055685</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>18.382103</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>1</td>\n",
       "      <td>105057</td>\n",
       "      <td>...</td>\n",
       "      <td>D00011589</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Friday</td>\n",
       "      <td>4th</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161219 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        note id  person id  age gender source value        BMI  \\\n",
       "0        101058         29   81                   F  25.247087   \n",
       "1         57801         64   60                   F  24.376249   \n",
       "2         71288         64   60                   F  24.376249   \n",
       "3        135104         64   60                   F  24.376249   \n",
       "4        221210         71   94                   M  27.963140   \n",
       "...         ...        ...  ...                 ...        ...   \n",
       "161214   297111    4055249    1                   M  23.700428   \n",
       "161215   297455    4055328    1                   M  20.612160   \n",
       "161216   297761    4055407    1                   M  12.502703   \n",
       "161217   297753    4055558    4                   F  14.365794   \n",
       "161218   298112    4055685    1                   M  18.382103   \n",
       "\n",
       "       admission department   division   ward  asa class  surgeon id  ...  \\\n",
       "0           General Surgery  Admission  NUGW2          2        9885  ...   \n",
       "1            Otolaryngology  Admission    102          2        6194  ...   \n",
       "2            Otolaryngology  Admission    102          3        6194  ...   \n",
       "3            Otolaryngology  Admission    102          3        6194  ...   \n",
       "4               Orthopedics  Admission     41          2       29473  ...   \n",
       "...                     ...        ...    ...        ...         ...  ...   \n",
       "161214    Pediatric Surgery  Admission     5A          1      100613  ...   \n",
       "161215    Pediatric Urology        Day   PDSC          1        6259  ...   \n",
       "161216    Pediatric Surgery  Admission     5A          2      105057  ...   \n",
       "161217    Pediatric Surgery  Admission     5A          2      105057  ...   \n",
       "161218    Pediatric Surgery  Admission     5A          1      105057  ...   \n",
       "\n",
       "       condition source value surgery room previous surgery emergency status  \\\n",
       "0                   D00002196          203                N                N   \n",
       "1                   D00003798          504                N                N   \n",
       "2                   D00003798          504                Y                N   \n",
       "3                   D00003798          504                Y                N   \n",
       "4                   D00018711          108                N                N   \n",
       "...                       ...          ...              ...              ...   \n",
       "161214              D00011688            5                N                Y   \n",
       "161215              D00016707            7                N                N   \n",
       "161216              D00011524            5                N                N   \n",
       "161217              D00004831            5                N                N   \n",
       "161218              D00011589            5                N                N   \n",
       "\n",
       "       op timing day of the week week of the month      month  \\\n",
       "0            TF2        Thursday               4th    October   \n",
       "1             8A          Friday               2nd    January   \n",
       "2            TF4          Monday               4th      April   \n",
       "3            TF2          Monday               3rd     August   \n",
       "4            TF4          Monday               5th      March   \n",
       "...          ...             ...               ...        ...   \n",
       "161214       etc         Tuesday               2nd  September   \n",
       "161215        8A          Monday               4th  September   \n",
       "161216        8A       Wednesday               3rd  September   \n",
       "161217       TF6       Wednesday               3rd  September   \n",
       "161218        8A          Friday               4th  September   \n",
       "\n",
       "       surgeon estimated op time surgery duration  \n",
       "0                            130               66  \n",
       "1                            300              130  \n",
       "2                            100               85  \n",
       "3                            100               83  \n",
       "4                            100               63  \n",
       "...                          ...              ...  \n",
       "161214                       200              123  \n",
       "161215                       130               45  \n",
       "161216                       130               43  \n",
       "161217                       130               82  \n",
       "161218                       130               75  \n",
       "\n",
       "[161219 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 현재 파이썬 코드의 파일 경로\n",
    "current_path = os.getcwd()  # 현재 작업 디렉토리를 가져옵니다.\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = os.path.join(current_path, 'filtered_data.csv')  # User uploaded fioytle to this path\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61344     122\n",
       "137241     48\n",
       "139478     76\n",
       "113549     36\n",
       "149411    127\n",
       "         ... \n",
       "119879     76\n",
       "103694     57\n",
       "131932    311\n",
       "146867     82\n",
       "121958     57\n",
       "Name: surgery duration, Length: 128975, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Removing unnecessary columns\n",
    "df.drop(columns=['note id', 'person id', 'surgeon estimated op time', 'final op name'], inplace=True)\n",
    "\n",
    "# Encoding binary columns\n",
    "binary_cols = ['condition source value', 'op code', 'surgeon id', 'ward', 'admission department', 'surgery room']\n",
    "for col in binary_cols:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "# One-hot encoding for other categorical columns\n",
    "one_hot_cols = ['surgical department', 'op timing', 'month', 'anesthesia type', \n",
    "                'day of the week', 'asa class', 'week of the month', \n",
    "                'division', 'previous surgery', 'emergency status', 'gender source value']\n",
    "df_encoded = pd.get_dummies(df, columns=one_hot_cols)\n",
    "\n",
    "# Splitting the data\n",
    "X_all = df_encoded.drop(\"surgery duration\", axis=1)\n",
    "y_all = df_encoded[\"surgery duration\"]\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the first few rows of the resulting dataframe\n",
    "X_train_all\n",
    "y_train_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 29.59938614649006, RMSE: 46.86902026895335, R²: 0.8155588209914891\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = CatBoostRegressor(iterations=100, random_state=42)\n",
    "    model.fit(X_train_dept, y_train_dept, verbose=False)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_cb = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_cb = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_cb = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_cb}, RMSE: {rmse_cb}, R²: {r2_cb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 91.7602875\ttotal: 17.1ms\tremaining: 1.69s\n",
      "1:\tlearn: 84.5750810\ttotal: 27.1ms\tremaining: 1.33s\n",
      "2:\tlearn: 81.3295372\ttotal: 35.6ms\tremaining: 1.15s\n",
      "3:\tlearn: 79.5957721\ttotal: 42.3ms\tremaining: 1.01s\n",
      "4:\tlearn: 78.3425860\ttotal: 48.2ms\tremaining: 917ms\n",
      "5:\tlearn: 77.0335198\ttotal: 54.7ms\tremaining: 856ms\n",
      "6:\tlearn: 76.4869700\ttotal: 60.6ms\tremaining: 806ms\n",
      "7:\tlearn: 75.2808840\ttotal: 66.4ms\tremaining: 763ms\n",
      "8:\tlearn: 74.3139224\ttotal: 73ms\tremaining: 738ms\n",
      "9:\tlearn: 74.0466624\ttotal: 79.3ms\tremaining: 713ms\n",
      "10:\tlearn: 73.5176541\ttotal: 84.4ms\tremaining: 683ms\n",
      "11:\tlearn: 73.0535794\ttotal: 90.2ms\tremaining: 661ms\n",
      "12:\tlearn: 72.5645112\ttotal: 95.9ms\tremaining: 642ms\n",
      "13:\tlearn: 71.7214923\ttotal: 101ms\tremaining: 623ms\n",
      "14:\tlearn: 71.2680946\ttotal: 108ms\tremaining: 614ms\n",
      "15:\tlearn: 70.3048047\ttotal: 114ms\tremaining: 596ms\n",
      "16:\tlearn: 70.1467237\ttotal: 119ms\tremaining: 582ms\n",
      "17:\tlearn: 69.7995100\ttotal: 125ms\tremaining: 569ms\n",
      "18:\tlearn: 69.3604244\ttotal: 130ms\tremaining: 556ms\n",
      "19:\tlearn: 69.1179037\ttotal: 136ms\tremaining: 546ms\n",
      "20:\tlearn: 68.7596402\ttotal: 142ms\tremaining: 534ms\n",
      "21:\tlearn: 68.4493155\ttotal: 147ms\tremaining: 523ms\n",
      "22:\tlearn: 68.1329853\ttotal: 154ms\tremaining: 516ms\n",
      "23:\tlearn: 67.9094249\ttotal: 161ms\tremaining: 511ms\n",
      "24:\tlearn: 67.4599648\ttotal: 169ms\tremaining: 506ms\n",
      "25:\tlearn: 67.1449693\ttotal: 176ms\tremaining: 500ms\n",
      "26:\tlearn: 66.8629792\ttotal: 182ms\tremaining: 492ms\n",
      "27:\tlearn: 66.5284203\ttotal: 189ms\tremaining: 486ms\n",
      "28:\tlearn: 66.2234651\ttotal: 195ms\tremaining: 477ms\n",
      "29:\tlearn: 65.9382965\ttotal: 202ms\tremaining: 472ms\n",
      "30:\tlearn: 65.6545391\ttotal: 209ms\tremaining: 464ms\n",
      "31:\tlearn: 65.3881808\ttotal: 215ms\tremaining: 458ms\n",
      "32:\tlearn: 65.1454575\ttotal: 223ms\tremaining: 452ms\n",
      "33:\tlearn: 64.9289454\ttotal: 228ms\tremaining: 442ms\n",
      "34:\tlearn: 64.6927869\ttotal: 235ms\tremaining: 436ms\n",
      "35:\tlearn: 64.5299353\ttotal: 240ms\tremaining: 428ms\n",
      "36:\tlearn: 64.4223405\ttotal: 246ms\tremaining: 419ms\n",
      "37:\tlearn: 64.2494138\ttotal: 253ms\tremaining: 412ms\n",
      "38:\tlearn: 64.0852876\ttotal: 258ms\tremaining: 404ms\n",
      "39:\tlearn: 63.9555645\ttotal: 264ms\tremaining: 396ms\n",
      "40:\tlearn: 63.8608055\ttotal: 270ms\tremaining: 388ms\n",
      "41:\tlearn: 63.5848048\ttotal: 275ms\tremaining: 380ms\n",
      "42:\tlearn: 63.4621246\ttotal: 281ms\tremaining: 372ms\n",
      "43:\tlearn: 63.3945848\ttotal: 286ms\tremaining: 364ms\n",
      "44:\tlearn: 63.2362122\ttotal: 291ms\tremaining: 356ms\n",
      "45:\tlearn: 63.1215100\ttotal: 297ms\tremaining: 349ms\n",
      "46:\tlearn: 63.0444606\ttotal: 302ms\tremaining: 341ms\n",
      "47:\tlearn: 62.9020147\ttotal: 308ms\tremaining: 333ms\n",
      "48:\tlearn: 62.8385998\ttotal: 314ms\tremaining: 326ms\n",
      "49:\tlearn: 62.7078438\ttotal: 319ms\tremaining: 319ms\n",
      "50:\tlearn: 62.5491470\ttotal: 325ms\tremaining: 312ms\n",
      "51:\tlearn: 62.4333032\ttotal: 331ms\tremaining: 306ms\n",
      "52:\tlearn: 62.2409131\ttotal: 337ms\tremaining: 299ms\n",
      "53:\tlearn: 62.0953981\ttotal: 343ms\tremaining: 292ms\n",
      "54:\tlearn: 61.9884409\ttotal: 349ms\tremaining: 285ms\n",
      "55:\tlearn: 61.8693282\ttotal: 355ms\tremaining: 279ms\n",
      "56:\tlearn: 61.7242303\ttotal: 361ms\tremaining: 272ms\n",
      "57:\tlearn: 61.6425693\ttotal: 366ms\tremaining: 265ms\n",
      "58:\tlearn: 61.5479314\ttotal: 371ms\tremaining: 258ms\n",
      "59:\tlearn: 61.4636028\ttotal: 377ms\tremaining: 251ms\n",
      "60:\tlearn: 61.3810998\ttotal: 383ms\tremaining: 245ms\n",
      "61:\tlearn: 61.3028359\ttotal: 389ms\tremaining: 238ms\n",
      "62:\tlearn: 61.2302940\ttotal: 395ms\tremaining: 232ms\n",
      "63:\tlearn: 61.1636666\ttotal: 401ms\tremaining: 225ms\n",
      "64:\tlearn: 61.1069828\ttotal: 407ms\tremaining: 219ms\n",
      "65:\tlearn: 61.0514394\ttotal: 413ms\tremaining: 213ms\n",
      "66:\tlearn: 60.9676015\ttotal: 420ms\tremaining: 207ms\n",
      "67:\tlearn: 60.8687364\ttotal: 426ms\tremaining: 200ms\n",
      "68:\tlearn: 60.7334284\ttotal: 432ms\tremaining: 194ms\n",
      "69:\tlearn: 60.6611886\ttotal: 437ms\tremaining: 187ms\n",
      "70:\tlearn: 60.5890153\ttotal: 444ms\tremaining: 181ms\n",
      "71:\tlearn: 60.4761935\ttotal: 450ms\tremaining: 175ms\n",
      "72:\tlearn: 60.4197476\ttotal: 455ms\tremaining: 168ms\n",
      "73:\tlearn: 60.3273703\ttotal: 461ms\tremaining: 162ms\n",
      "74:\tlearn: 60.2918464\ttotal: 467ms\tremaining: 156ms\n",
      "75:\tlearn: 60.2100371\ttotal: 473ms\tremaining: 150ms\n",
      "76:\tlearn: 60.1554122\ttotal: 479ms\tremaining: 143ms\n",
      "77:\tlearn: 60.0871815\ttotal: 485ms\tremaining: 137ms\n",
      "78:\tlearn: 60.0360253\ttotal: 490ms\tremaining: 130ms\n",
      "79:\tlearn: 59.9607309\ttotal: 496ms\tremaining: 124ms\n",
      "80:\tlearn: 59.8610714\ttotal: 501ms\tremaining: 118ms\n",
      "81:\tlearn: 59.7881572\ttotal: 507ms\tremaining: 111ms\n",
      "82:\tlearn: 59.6359161\ttotal: 513ms\tremaining: 105ms\n",
      "83:\tlearn: 59.5887758\ttotal: 518ms\tremaining: 98.7ms\n",
      "84:\tlearn: 59.5013141\ttotal: 524ms\tremaining: 92.5ms\n",
      "85:\tlearn: 59.4406357\ttotal: 530ms\tremaining: 86.3ms\n",
      "86:\tlearn: 59.3659376\ttotal: 536ms\tremaining: 80.1ms\n",
      "87:\tlearn: 59.3158857\ttotal: 542ms\tremaining: 73.9ms\n",
      "88:\tlearn: 59.2555488\ttotal: 547ms\tremaining: 67.6ms\n",
      "89:\tlearn: 59.2032451\ttotal: 552ms\tremaining: 61.3ms\n",
      "90:\tlearn: 59.1428105\ttotal: 557ms\tremaining: 55.1ms\n",
      "91:\tlearn: 59.1125230\ttotal: 563ms\tremaining: 48.9ms\n",
      "92:\tlearn: 59.0251602\ttotal: 568ms\tremaining: 42.7ms\n",
      "93:\tlearn: 58.9671344\ttotal: 574ms\tremaining: 36.6ms\n",
      "94:\tlearn: 58.9115882\ttotal: 579ms\tremaining: 30.5ms\n",
      "95:\tlearn: 58.8783374\ttotal: 584ms\tremaining: 24.3ms\n",
      "96:\tlearn: 58.8218100\ttotal: 591ms\tremaining: 18.3ms\n",
      "97:\tlearn: 58.7731525\ttotal: 596ms\tremaining: 12.2ms\n",
      "98:\tlearn: 58.7211669\ttotal: 601ms\tremaining: 6.07ms\n",
      "99:\tlearn: 58.6657022\ttotal: 608ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37.65593124629112, 60.75771181898664, 0.6900519143082409)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training a model on the entire dataset\n",
    "full_model = CatBoostRegressor(iterations=100, random_state=42)\n",
    "full_model.fit(X_train_all, y_train_all)\n",
    "\n",
    "# Predicting on the test set\n",
    "full_model_predictions = full_model.predict(X_test_all)\n",
    "\n",
    "# Evaluating the full model's performance\n",
    "full_model_mae = mean_absolute_error(y_test_all, full_model_predictions)\n",
    "full_model_rmse = np.sqrt(mean_squared_error(y_test_all, full_model_predictions))\n",
    "full_model_r2 = r2_score(y_test_all, full_model_predictions)\n",
    "\n",
    "full_model_mae, full_model_rmse, full_model_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 16.67870301451433, RMSE: 31.662393537060968, R²: 0.9158268414503081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_rf = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_rf = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_rf}, RMSE: {rmse_rf}, R²: {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 50.2211215236737, RMSE: 76.9795817900624, R²: 0.5024494234514032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_lr = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_lr = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_lr}, RMSE: {rmse_lr}, R²: {r2_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 22.601232791322957, RMSE: 37.310003900594154, R²: 0.883120935189753\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = XGBRegressor(random_state=42)\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_xgb = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_xgb = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_xgb}, RMSE: {rmse_xgb}, R²: {r2_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 8.789387172807343, RMSE: 33.36653615556264, R²: 0.9065222205584245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_dt = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_dt = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_dt}, RMSE: {rmse_dt}, R²: {r2_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'General Surgery': 9.49593383873191,\n",
       " 'Otolaryngology': 10.50947459086994,\n",
       " 'Orthopedics': 10.144918821407096,\n",
       " 'Ophthalmology': 3.6727115716753023,\n",
       " 'Obstetrics & Gynecology': 10.022933794893985,\n",
       " 'Urology': 6.10071371927042,\n",
       " 'Plastic Surgery': 11.034029850746268,\n",
       " 'Neurosurgery': 12.349152542372881,\n",
       " 'Cardiovascular Thoracic Surgery': 12.488384371700105,\n",
       " 'Pediatric Otolaryngology': 6.259421560035057,\n",
       " 'Pediatric Orthopedics': 13.420986093552465,\n",
       " 'Pediatric Thoracic Surgery': 13.419270833333334,\n",
       " 'Pediatric Urology': 8.743455497382199,\n",
       " 'Pediatric Surgery': 5.699167657550535,\n",
       " 'Pediatric Ophthalmology': 3.1666666666666665,\n",
       " 'Pediatric Plastic Surgery': 8.358916478555305,\n",
       " 'Pediatric Neurosurgery': 14.060085836909872}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting the code to calculate and display the MAE for each department\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Dictionary to store MAE for each department\n",
    "department_mae = {}\n",
    "\n",
    "for dept, model in models.items():\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # Check if the department has test data\n",
    "    if len(dept_indices) > 0:\n",
    "        # Calculate predictions for this department\n",
    "        dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "        # Extract the actual values for this department from the whole test dataset\n",
    "        actual_values = y_test_all.loc[dept_indices]\n",
    "\n",
    "        # Calculate MAE for this department\n",
    "        mae = mean_absolute_error(actual_values, dept_predictions)\n",
    "        department_mae[dept] = mae\n",
    "\n",
    "department_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 29172, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score 156.203071\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 935\n",
      "[LightGBM] [Info] Number of data points in the train set: 9417, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 138.766380\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 13293, number of used features: 64\n",
      "[LightGBM] [Info] Start training from score 133.600617\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 13949, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 57.941501\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 9208, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 131.215030\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 10192, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 114.860184\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 6768, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 139.017878\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 5749, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 240.737520\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 7472, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 233.097698\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 783\n",
      "[LightGBM] [Info] Number of data points in the train set: 4611, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 84.449360\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 955\n",
      "[LightGBM] [Info] Number of data points in the train set: 3124, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 143.928297\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 595\n",
      "[LightGBM] [Info] Number of data points in the train set: 1500, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 272.156000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 2380, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 112.698319\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 3216, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 97.698694\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 6285, number of used features: 56\n",
      "[LightGBM] [Info] Start training from score 56.602864\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 1699, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 115.839906\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 499\n",
      "[LightGBM] [Info] Number of data points in the train set: 932, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 295.402361\n",
      "Ensemble MAE: 28.908992268322443, RMSE: 46.733625866924136, R²: 0.8166229026907913\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = LGBMRegressor(random_state=42)\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_lgbm = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_lgbm = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_lgbm = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_lgbm}, RMSE: {rmse_lgbm}, R²: {r2_lgbm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>16.68</td>\n",
       "      <td>31.66</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>50.22</td>\n",
       "      <td>76.98</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>22.60</td>\n",
       "      <td>37.31</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>8.79</td>\n",
       "      <td>33.37</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>28.91</td>\n",
       "      <td>46.73</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MAE   RMSE    R2\n",
       "Random Forest      16.68  31.66  0.92\n",
       "Linear Regression  50.22  76.98  0.50\n",
       "XGBoost            22.60  37.31  0.88\n",
       "Decision Tree       8.79  33.37  0.91\n",
       "LightGBM           28.91  46.73  0.82"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 값을 딕셔너리 형태로 정리\n",
    "ensemble_results = {\n",
    "    \"Random Forest\": {\"MAE\": mae_rf, \"RMSE\": rmse_rf, \"R2\": r2_rf},\n",
    "    \"Linear Regression\": {\"MAE\": mae_lr, \"RMSE\": rmse_lr, \"R2\": r2_lr},\n",
    "    \"XGBoost\": {\"MAE\": mae_xgb, \"RMSE\": rmse_xgb, \"R2\": r2_xgb},\n",
    "    \"Decision Tree\": {\"MAE\": mae_dt, \"RMSE\": rmse_dt, \"R2\": r2_dt},\n",
    "    \"LightGBM\": {\"MAE\": mae_lgbm, \"RMSE\": rmse_lgbm, \"R2\": r2_lgbm}\n",
    "}\n",
    "\n",
    "# 결과를 DataFrame으로 변환 및 소수점 둘째 자리 반올림\n",
    "results_df = pd.DataFrame(ensemble_results).T.round(2)\n",
    "\n",
    "results_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surgical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
