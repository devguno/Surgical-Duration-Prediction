{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note id</th>\n",
       "      <th>person id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender source value</th>\n",
       "      <th>BMI</th>\n",
       "      <th>admission department</th>\n",
       "      <th>division</th>\n",
       "      <th>ward</th>\n",
       "      <th>asa class</th>\n",
       "      <th>surgeon id</th>\n",
       "      <th>...</th>\n",
       "      <th>condition source value</th>\n",
       "      <th>surgery room</th>\n",
       "      <th>previous surgery</th>\n",
       "      <th>emergency status</th>\n",
       "      <th>op timing</th>\n",
       "      <th>day of the week</th>\n",
       "      <th>week of the month</th>\n",
       "      <th>month</th>\n",
       "      <th>surgeon estimated op time</th>\n",
       "      <th>surgery duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101058</td>\n",
       "      <td>29</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>25.247087</td>\n",
       "      <td>General Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>NUGW2</td>\n",
       "      <td>2</td>\n",
       "      <td>9885</td>\n",
       "      <td>...</td>\n",
       "      <td>D00002196</td>\n",
       "      <td>203</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>TF2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4th</td>\n",
       "      <td>October</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57801</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>24.376249</td>\n",
       "      <td>Otolaryngology</td>\n",
       "      <td>Admission</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>6194</td>\n",
       "      <td>...</td>\n",
       "      <td>D00003798</td>\n",
       "      <td>504</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2nd</td>\n",
       "      <td>January</td>\n",
       "      <td>300</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71288</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>24.376249</td>\n",
       "      <td>Otolaryngology</td>\n",
       "      <td>Admission</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>6194</td>\n",
       "      <td>...</td>\n",
       "      <td>D00003798</td>\n",
       "      <td>504</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>TF4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4th</td>\n",
       "      <td>April</td>\n",
       "      <td>100</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135104</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>24.376249</td>\n",
       "      <td>Otolaryngology</td>\n",
       "      <td>Admission</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>6194</td>\n",
       "      <td>...</td>\n",
       "      <td>D00003798</td>\n",
       "      <td>504</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>TF2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3rd</td>\n",
       "      <td>August</td>\n",
       "      <td>100</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221210</td>\n",
       "      <td>71</td>\n",
       "      <td>94</td>\n",
       "      <td>M</td>\n",
       "      <td>27.963140</td>\n",
       "      <td>Orthopedics</td>\n",
       "      <td>Admission</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>29473</td>\n",
       "      <td>...</td>\n",
       "      <td>D00018711</td>\n",
       "      <td>108</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>TF4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>5th</td>\n",
       "      <td>March</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161214</th>\n",
       "      <td>297111</td>\n",
       "      <td>4055249</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>23.700428</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>1</td>\n",
       "      <td>100613</td>\n",
       "      <td>...</td>\n",
       "      <td>D00011688</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>etc</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2nd</td>\n",
       "      <td>September</td>\n",
       "      <td>200</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161215</th>\n",
       "      <td>297455</td>\n",
       "      <td>4055328</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>20.612160</td>\n",
       "      <td>Pediatric Urology</td>\n",
       "      <td>Day</td>\n",
       "      <td>PDSC</td>\n",
       "      <td>1</td>\n",
       "      <td>6259</td>\n",
       "      <td>...</td>\n",
       "      <td>D00016707</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4th</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161216</th>\n",
       "      <td>297761</td>\n",
       "      <td>4055407</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>12.502703</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>2</td>\n",
       "      <td>105057</td>\n",
       "      <td>...</td>\n",
       "      <td>D00011524</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3rd</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161217</th>\n",
       "      <td>297753</td>\n",
       "      <td>4055558</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>14.365794</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>2</td>\n",
       "      <td>105057</td>\n",
       "      <td>...</td>\n",
       "      <td>D00004831</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>TF6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3rd</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161218</th>\n",
       "      <td>298112</td>\n",
       "      <td>4055685</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>18.382103</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>1</td>\n",
       "      <td>105057</td>\n",
       "      <td>...</td>\n",
       "      <td>D00011589</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Friday</td>\n",
       "      <td>4th</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161219 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        note id  person id  age gender source value        BMI  \\\n",
       "0        101058         29   81                   F  25.247087   \n",
       "1         57801         64   60                   F  24.376249   \n",
       "2         71288         64   60                   F  24.376249   \n",
       "3        135104         64   60                   F  24.376249   \n",
       "4        221210         71   94                   M  27.963140   \n",
       "...         ...        ...  ...                 ...        ...   \n",
       "161214   297111    4055249    1                   M  23.700428   \n",
       "161215   297455    4055328    1                   M  20.612160   \n",
       "161216   297761    4055407    1                   M  12.502703   \n",
       "161217   297753    4055558    4                   F  14.365794   \n",
       "161218   298112    4055685    1                   M  18.382103   \n",
       "\n",
       "       admission department   division   ward  asa class  surgeon id  ...  \\\n",
       "0           General Surgery  Admission  NUGW2          2        9885  ...   \n",
       "1            Otolaryngology  Admission    102          2        6194  ...   \n",
       "2            Otolaryngology  Admission    102          3        6194  ...   \n",
       "3            Otolaryngology  Admission    102          3        6194  ...   \n",
       "4               Orthopedics  Admission     41          2       29473  ...   \n",
       "...                     ...        ...    ...        ...         ...  ...   \n",
       "161214    Pediatric Surgery  Admission     5A          1      100613  ...   \n",
       "161215    Pediatric Urology        Day   PDSC          1        6259  ...   \n",
       "161216    Pediatric Surgery  Admission     5A          2      105057  ...   \n",
       "161217    Pediatric Surgery  Admission     5A          2      105057  ...   \n",
       "161218    Pediatric Surgery  Admission     5A          1      105057  ...   \n",
       "\n",
       "       condition source value surgery room previous surgery emergency status  \\\n",
       "0                   D00002196          203                N                N   \n",
       "1                   D00003798          504                N                N   \n",
       "2                   D00003798          504                Y                N   \n",
       "3                   D00003798          504                Y                N   \n",
       "4                   D00018711          108                N                N   \n",
       "...                       ...          ...              ...              ...   \n",
       "161214              D00011688            5                N                Y   \n",
       "161215              D00016707            7                N                N   \n",
       "161216              D00011524            5                N                N   \n",
       "161217              D00004831            5                N                N   \n",
       "161218              D00011589            5                N                N   \n",
       "\n",
       "       op timing day of the week week of the month      month  \\\n",
       "0            TF2        Thursday               4th    October   \n",
       "1             8A          Friday               2nd    January   \n",
       "2            TF4          Monday               4th      April   \n",
       "3            TF2          Monday               3rd     August   \n",
       "4            TF4          Monday               5th      March   \n",
       "...          ...             ...               ...        ...   \n",
       "161214       etc         Tuesday               2nd  September   \n",
       "161215        8A          Monday               4th  September   \n",
       "161216        8A       Wednesday               3rd  September   \n",
       "161217       TF6       Wednesday               3rd  September   \n",
       "161218        8A          Friday               4th  September   \n",
       "\n",
       "       surgeon estimated op time surgery duration  \n",
       "0                            130               66  \n",
       "1                            300              130  \n",
       "2                            100               85  \n",
       "3                            100               83  \n",
       "4                            100               63  \n",
       "...                          ...              ...  \n",
       "161214                       200              123  \n",
       "161215                       130               45  \n",
       "161216                       130               43  \n",
       "161217                       130               82  \n",
       "161218                       130               75  \n",
       "\n",
       "[161219 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 현재 파이썬 코드의 파일 경로\n",
    "current_path = os.getcwd()  # 현재 작업 디렉토리를 가져옵니다.\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = os.path.join(current_path, 'filtered_data_9dep.csv')  # User uploaded fioytle to this path\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70.8192520732668, 94.3469303146079, 8901.343259789479, 0.2590043404892589)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculating MAE, RMSE, MSE, and R² for the surgeon's estimated operation time\n",
    "surgeon_mae = mean_absolute_error(df['surgery duration'], df['surgeon estimated op time'])\n",
    "surgeon_rmse = np.sqrt(mean_squared_error(df['surgery duration'], df['surgeon estimated op time']))\n",
    "surgeon_mse = mean_squared_error(df['surgery duration'], df['surgeon estimated op time'])\n",
    "surgeon_r2 = r2_score(df['surgery duration'], df['surgeon estimated op time'])\n",
    "\n",
    "surgeon_mae, surgeon_rmse, surgeon_mse, surgeon_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61344     122\n",
       "137241     48\n",
       "139478     76\n",
       "113549     36\n",
       "149411    127\n",
       "         ... \n",
       "119879     76\n",
       "103694     57\n",
       "131932    311\n",
       "146867     82\n",
       "121958     57\n",
       "Name: surgery duration, Length: 128975, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Removing unnecessary columns\n",
    "df.drop(columns=['note id', 'person id', 'surgeon estimated op time', 'final op name'], inplace=True)\n",
    "\n",
    "# Encoding binary columns\n",
    "binary_cols = ['condition source value']\n",
    "for col in binary_cols:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "# One-hot encoding for other categorical columns\n",
    "one_hot_cols = ['surgical department', 'op timing', 'month', 'anesthesia type',\n",
    "                'day of the week', 'asa class', 'week of the month', \n",
    "                'division', 'previous surgery', 'emergency status', 'gender source value', 'surgeon id', 'ward', \n",
    "                'admission department', 'surgery room', 'op code']\n",
    "df_encoded = pd.get_dummies(df, columns=one_hot_cols)\n",
    "\n",
    "# Splitting the data\n",
    "X_all = df_encoded.drop(\"surgery duration\", axis=1)\n",
    "y_all = df_encoded[\"surgery duration\"]\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the first few rows of the resulting dataframe\n",
    "X_train_all\n",
    "y_train_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 16.289982890873755, RMSE: 31.442222613735787, R²: 0.9169934018567466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cross_val_scores_rf = {}\n",
    "\n",
    "# Preparing department-specific datasets\n",
    "departments = df['surgical department'].unique()\n",
    "department_models = {}\n",
    "predictions = {}\n",
    "\n",
    "\n",
    "# Training models for each department\n",
    "for dept in departments:\n",
    "    # Adjusting column name\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # Filtering data for the department\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration'] \n",
    "\n",
    "    # Splitting the data\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Training the model with cross-validation\n",
    "    department_model = RandomForestRegressor(random_state=42)\n",
    "    cv_scores_rf = cross_val_score(department_model, X_dept, y_dept, cv=5)\n",
    "    cross_val_scores_rf[dept] = cv_scores_rf.mean()\n",
    "\n",
    "    # Training and saving the final model\n",
    "    department_model.fit(X_train_dept, y_train_dept)\n",
    "    department_models[dept] = department_model\n",
    "\n",
    "    # Making predictions on the test dataset\n",
    "    predictions[dept] = department_model.predict(X_test_dept)\n",
    "\n",
    "\n",
    "# Preparing for ensemble\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# Applying each department-specific model to the entire test dataset\n",
    "for dept, department_model in department_models.items():\n",
    "    # Adjusting column name\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # Indices of test data belonging to the department\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # Calculating predictions for the department\n",
    "    dept_predictions = department_model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # Updating the final prediction array\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# Evaluating performance\n",
    "mae_rf = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_rf = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "# The code is now updated with model names changed to 'department_model'\n",
    "mae_rf, rmse_rf, r2_rf\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_rf}, RMSE: {rmse_rf}, R²: {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 28.833596684366757, RMSE: 45.86811972717231, R²: 0.8233522890826517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "cross_val_scores_xgb = {}\n",
    "\n",
    "# Preparing department-specific datasets\n",
    "departments = df['surgical department'].unique()\n",
    "department_models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Training models for each department with XGBoost\n",
    "for dept in departments:\n",
    "    # Adjusting column name\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # Filtering data for the department\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # Splitting the data\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Training the model with cross-validation\n",
    "    department_model = XGBRegressor(random_state=42)\n",
    "    cv_scores_xgb = cross_val_score(department_model, X_dept, y_dept, cv=5)\n",
    "    cross_val_scores_xgb[dept] = cv_scores_xgb.mean()\n",
    "\n",
    "    # Training and saving the final model\n",
    "    department_model.fit(X_train_dept, y_train_dept)\n",
    "    department_models[dept] = department_model\n",
    "\n",
    "    # Making predictions on the test dataset\n",
    "    predictions[dept] = department_model.predict(X_test_dept)\n",
    "\n",
    "# Preparing for ensemble\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# Applying each department-specific model to the entire test dataset\n",
    "for dept, department_model in department_models.items():\n",
    "    # Adjusting column name\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # Indices of test data belonging to the department\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # Calculating predictions for the department\n",
    "    dept_predictions = department_model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # Updating the final prediction array\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# Evaluating performance\n",
    "mae_xgb = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_xgb = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_xgb}, RMSE: {rmse_xgb}, R²: {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1360\n",
      "[LightGBM] [Info] Number of data points in the train set: 32389, number of used features: 379\n",
      "[LightGBM] [Info] Start training from score 152.524777\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1352\n",
      "[LightGBM] [Info] Number of data points in the train set: 32389, number of used features: 375\n",
      "[LightGBM] [Info] Start training from score 151.163574\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1365\n",
      "[LightGBM] [Info] Number of data points in the train set: 32390, number of used features: 381\n",
      "[LightGBM] [Info] Start training from score 145.732942\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1304\n",
      "[LightGBM] [Info] Number of data points in the train set: 32390, number of used features: 353\n",
      "[LightGBM] [Info] Start training from score 151.735073\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1356\n",
      "[LightGBM] [Info] Number of data points in the train set: 32390, number of used features: 378\n",
      "[LightGBM] [Info] Start training from score 148.144890\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1358\n",
      "[LightGBM] [Info] Number of data points in the train set: 32389, number of used features: 377\n",
      "[LightGBM] [Info] Start training from score 150.122511\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 949\n",
      "[LightGBM] [Info] Number of data points in the train set: 14028, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score 119.086185\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 957\n",
      "[LightGBM] [Info] Number of data points in the train set: 14029, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 116.437380\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 14029, number of used features: 189\n",
      "[LightGBM] [Info] Start training from score 120.449070\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 959\n",
      "[LightGBM] [Info] Number of data points in the train set: 14029, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score 131.148264\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 969\n",
      "[LightGBM] [Info] Number of data points in the train set: 14029, number of used features: 188\n",
      "[LightGBM] [Info] Start training from score 118.105638\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 960\n",
      "[LightGBM] [Info] Number of data points in the train set: 14028, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score 121.372042\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 16417, number of used features: 298\n",
      "[LightGBM] [Info] Start training from score 136.355302\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1170\n",
      "[LightGBM] [Info] Number of data points in the train set: 16417, number of used features: 283\n",
      "[LightGBM] [Info] Start training from score 136.605714\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1172\n",
      "[LightGBM] [Info] Number of data points in the train set: 16418, number of used features: 283\n",
      "[LightGBM] [Info] Start training from score 135.374650\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1151\n",
      "[LightGBM] [Info] Number of data points in the train set: 16418, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 133.460836\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1157\n",
      "[LightGBM] [Info] Number of data points in the train set: 16418, number of used features: 278\n",
      "[LightGBM] [Info] Start training from score 137.338896\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1171\n",
      "[LightGBM] [Info] Number of data points in the train set: 16417, number of used features: 283\n",
      "[LightGBM] [Info] Start training from score 135.178352\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 870\n",
      "[LightGBM] [Info] Number of data points in the train set: 20235, number of used features: 147\n",
      "[LightGBM] [Info] Start training from score 58.722511\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 874\n",
      "[LightGBM] [Info] Number of data points in the train set: 20235, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 58.359822\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 863\n",
      "[LightGBM] [Info] Number of data points in the train set: 20235, number of used features: 143\n",
      "[LightGBM] [Info] Start training from score 56.665925\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 20235, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 56.539165\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 20236, number of used features: 134\n",
      "[LightGBM] [Info] Start training from score 56.739375\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 20235, number of used features: 143\n",
      "[LightGBM] [Info] Start training from score 57.477440\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 723\n",
      "[LightGBM] [Info] Number of data points in the train set: 9208, number of used features: 103\n",
      "[LightGBM] [Info] Start training from score 132.121199\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 727\n",
      "[LightGBM] [Info] Number of data points in the train set: 9208, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score 133.264553\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 712\n",
      "[LightGBM] [Info] Number of data points in the train set: 9208, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score 131.226216\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 724\n",
      "[LightGBM] [Info] Number of data points in the train set: 9208, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score 130.890964\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 722\n",
      "[LightGBM] [Info] Number of data points in the train set: 9208, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score 130.171264\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 721\n",
      "[LightGBM] [Info] Number of data points in the train set: 9208, number of used features: 103\n",
      "[LightGBM] [Info] Start training from score 131.215030\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 834\n",
      "[LightGBM] [Info] Number of data points in the train set: 12572, number of used features: 150\n",
      "[LightGBM] [Info] Start training from score 117.593462\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 829\n",
      "[LightGBM] [Info] Number of data points in the train set: 12573, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 117.396246\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 831\n",
      "[LightGBM] [Info] Number of data points in the train set: 12573, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 111.818579\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 12573, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 114.442456\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 827\n",
      "[LightGBM] [Info] Number of data points in the train set: 12573, number of used features: 147\n",
      "[LightGBM] [Info] Start training from score 115.027758\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 12572, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 114.789771\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 898\n",
      "[LightGBM] [Info] Number of data points in the train set: 8467, number of used features: 158\n",
      "[LightGBM] [Info] Start training from score 135.627967\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 904\n",
      "[LightGBM] [Info] Number of data points in the train set: 8467, number of used features: 158\n",
      "[LightGBM] [Info] Start training from score 133.721625\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 897\n",
      "[LightGBM] [Info] Number of data points in the train set: 8467, number of used features: 157\n",
      "[LightGBM] [Info] Start training from score 132.452108\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 883\n",
      "[LightGBM] [Info] Number of data points in the train set: 8467, number of used features: 149\n",
      "[LightGBM] [Info] Start training from score 139.620172\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 900\n",
      "[LightGBM] [Info] Number of data points in the train set: 8468, number of used features: 159\n",
      "[LightGBM] [Info] Start training from score 130.710085\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 903\n",
      "[LightGBM] [Info] Number of data points in the train set: 8467, number of used features: 159\n",
      "[LightGBM] [Info] Start training from score 133.551081\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 828\n",
      "[LightGBM] [Info] Number of data points in the train set: 6682, number of used features: 131\n",
      "[LightGBM] [Info] Start training from score 254.331039\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 6682, number of used features: 130\n",
      "[LightGBM] [Info] Start training from score 246.958994\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 838\n",
      "[LightGBM] [Info] Number of data points in the train set: 6682, number of used features: 135\n",
      "[LightGBM] [Info] Start training from score 244.732715\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 6683, number of used features: 123\n",
      "[LightGBM] [Info] Start training from score 241.690259\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 833\n",
      "[LightGBM] [Info] Number of data points in the train set: 6683, number of used features: 134\n",
      "[LightGBM] [Info] Start training from score 248.893012\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 832\n",
      "[LightGBM] [Info] Number of data points in the train set: 6682, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score 246.281652\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 856\n",
      "[LightGBM] [Info] Number of data points in the train set: 8973, number of used features: 138\n",
      "[LightGBM] [Info] Start training from score 236.408002\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 8973, number of used features: 135\n",
      "[LightGBM] [Info] Start training from score 242.911847\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 855\n",
      "[LightGBM] [Info] Number of data points in the train set: 8974, number of used features: 137\n",
      "[LightGBM] [Info] Start training from score 239.203700\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 826\n",
      "[LightGBM] [Info] Number of data points in the train set: 8974, number of used features: 127\n",
      "[LightGBM] [Info] Start training from score 236.240250\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 8974, number of used features: 137\n",
      "[LightGBM] [Info] Start training from score 242.521172\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 8973, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score 238.826814\n",
      "Ensemble MAE: 31.079823949805366, RMSE: 51.063841386696026, R²: 0.781066054382394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "cross_val_scores_lgbm = {}\n",
    "\n",
    "# Preparing department-specific datasets\n",
    "departments = df['surgical department'].unique()\n",
    "department_models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Training models for each department with LightGBM\n",
    "for dept in departments:\n",
    "    # Adjusting column name\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # Filtering data for the department\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # Splitting the data\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Training the model with cross-validation\n",
    "    department_model = LGBMRegressor(random_state=42)\n",
    "    cv_scores_lgbm = cross_val_score(department_model, X_dept, y_dept, cv=5)\n",
    "    cross_val_scores_lgbm[dept] = cv_scores_lgbm.mean()\n",
    "\n",
    "    # Training and saving the final model\n",
    "    department_model.fit(X_train_dept, y_train_dept)\n",
    "    department_models[dept] = department_model\n",
    "\n",
    "    # Making predictions on the test dataset\n",
    "    predictions[dept] = department_model.predict(X_test_dept)\n",
    "\n",
    "# Preparing for ensemble\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# Applying each department-specific model to the entire test dataset\n",
    "for dept, department_model in department_models.items():\n",
    "    # Adjusting column name\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # Indices of test data belonging to the department\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # Calculating predictions for the department\n",
    "    dept_predictions = department_model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # Updating the final prediction array\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# Evaluating performance\n",
    "mae_lgbm = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_lgbm = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_lgbm = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_lgbm}, RMSE: {rmse_lgbm}, R²: {r2_lgbm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 1566895.9045000311, RMSE: 230490717.0939277, R²: -4460597300831.962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Preparing department-specific datasets\n",
    "departments = df['surgical department'].unique()\n",
    "department_models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Training models for each department with Linear Regression\n",
    "for dept in departments:\n",
    "    # Adjusting column name\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # Filtering data for the department\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # Splitting the data\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Training the model\n",
    "    department_model = LinearRegression()\n",
    "    department_model.fit(X_train_dept, y_train_dept)\n",
    "    department_models[dept] = department_model\n",
    "\n",
    "    # Making predictions on the test dataset\n",
    "    predictions[dept] = department_model.predict(X_test_dept)\n",
    "\n",
    "# Preparing for ensemble\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# Applying each department-specific model to the entire test dataset\n",
    "for dept, department_model in department_models.items():\n",
    "    # Adjusting column name\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # Indices of test data belonging to the department\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # Calculating predictions for the department\n",
    "    dept_predictions = department_model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # Updating the final prediction array\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# Evaluating performance\n",
    "mae_lr = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_lr = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_lr}, RMSE: {rmse_lr}, R²: {r2_lr}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surgical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
