{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note id</th>\n",
       "      <th>person id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender source value</th>\n",
       "      <th>BMI</th>\n",
       "      <th>admission department</th>\n",
       "      <th>division</th>\n",
       "      <th>ward</th>\n",
       "      <th>asa class</th>\n",
       "      <th>surgeon id</th>\n",
       "      <th>...</th>\n",
       "      <th>condition source value</th>\n",
       "      <th>surgery room</th>\n",
       "      <th>previous surgery</th>\n",
       "      <th>emergency status</th>\n",
       "      <th>op timing</th>\n",
       "      <th>day of the week</th>\n",
       "      <th>week of the month</th>\n",
       "      <th>month</th>\n",
       "      <th>surgeon estimated op time</th>\n",
       "      <th>surgery duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101058</td>\n",
       "      <td>29</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>25.247087</td>\n",
       "      <td>General Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>NUGW2</td>\n",
       "      <td>2</td>\n",
       "      <td>9885</td>\n",
       "      <td>...</td>\n",
       "      <td>D00002196</td>\n",
       "      <td>203</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>TF2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4</td>\n",
       "      <td>October</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57801</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>24.376249</td>\n",
       "      <td>Otolaryngology</td>\n",
       "      <td>Admission</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>6194</td>\n",
       "      <td>...</td>\n",
       "      <td>D00003798</td>\n",
       "      <td>504</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2</td>\n",
       "      <td>January</td>\n",
       "      <td>300</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71288</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>24.376249</td>\n",
       "      <td>Otolaryngology</td>\n",
       "      <td>Admission</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>6194</td>\n",
       "      <td>...</td>\n",
       "      <td>D00003798</td>\n",
       "      <td>504</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>TF4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4</td>\n",
       "      <td>April</td>\n",
       "      <td>100</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135104</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "      <td>24.376249</td>\n",
       "      <td>Otolaryngology</td>\n",
       "      <td>Admission</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>6194</td>\n",
       "      <td>...</td>\n",
       "      <td>D00003798</td>\n",
       "      <td>504</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>TF2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>August</td>\n",
       "      <td>100</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221210</td>\n",
       "      <td>71</td>\n",
       "      <td>94</td>\n",
       "      <td>M</td>\n",
       "      <td>27.963140</td>\n",
       "      <td>Orthopedics</td>\n",
       "      <td>Admission</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>29473</td>\n",
       "      <td>...</td>\n",
       "      <td>D00018711</td>\n",
       "      <td>108</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>TF4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>5</td>\n",
       "      <td>March</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161214</th>\n",
       "      <td>297111</td>\n",
       "      <td>4055249</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>23.700428</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>1</td>\n",
       "      <td>100613</td>\n",
       "      <td>...</td>\n",
       "      <td>D00011688</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>etc</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2</td>\n",
       "      <td>September</td>\n",
       "      <td>200</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161215</th>\n",
       "      <td>297455</td>\n",
       "      <td>4055328</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>20.612160</td>\n",
       "      <td>Pediatric Urology</td>\n",
       "      <td>Day</td>\n",
       "      <td>PDSC</td>\n",
       "      <td>1</td>\n",
       "      <td>6259</td>\n",
       "      <td>...</td>\n",
       "      <td>D00016707</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161216</th>\n",
       "      <td>297761</td>\n",
       "      <td>4055407</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>12.502703</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>2</td>\n",
       "      <td>105057</td>\n",
       "      <td>...</td>\n",
       "      <td>D00011524</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161217</th>\n",
       "      <td>297753</td>\n",
       "      <td>4055558</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>14.365794</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>2</td>\n",
       "      <td>105057</td>\n",
       "      <td>...</td>\n",
       "      <td>D00004831</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>TF6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161218</th>\n",
       "      <td>298112</td>\n",
       "      <td>4055685</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>18.382103</td>\n",
       "      <td>Pediatric Surgery</td>\n",
       "      <td>Admission</td>\n",
       "      <td>5A</td>\n",
       "      <td>1</td>\n",
       "      <td>105057</td>\n",
       "      <td>...</td>\n",
       "      <td>D00011589</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8A</td>\n",
       "      <td>Friday</td>\n",
       "      <td>4</td>\n",
       "      <td>September</td>\n",
       "      <td>130</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161219 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        note id  person id  age gender source value        BMI  \\\n",
       "0        101058         29   81                   F  25.247087   \n",
       "1         57801         64   60                   F  24.376249   \n",
       "2         71288         64   60                   F  24.376249   \n",
       "3        135104         64   60                   F  24.376249   \n",
       "4        221210         71   94                   M  27.963140   \n",
       "...         ...        ...  ...                 ...        ...   \n",
       "161214   297111    4055249    1                   M  23.700428   \n",
       "161215   297455    4055328    1                   M  20.612160   \n",
       "161216   297761    4055407    1                   M  12.502703   \n",
       "161217   297753    4055558    4                   F  14.365794   \n",
       "161218   298112    4055685    1                   M  18.382103   \n",
       "\n",
       "       admission department   division   ward  asa class  surgeon id  ...  \\\n",
       "0           General Surgery  Admission  NUGW2          2        9885  ...   \n",
       "1            Otolaryngology  Admission    102          2        6194  ...   \n",
       "2            Otolaryngology  Admission    102          3        6194  ...   \n",
       "3            Otolaryngology  Admission    102          3        6194  ...   \n",
       "4               Orthopedics  Admission     41          2       29473  ...   \n",
       "...                     ...        ...    ...        ...         ...  ...   \n",
       "161214    Pediatric Surgery  Admission     5A          1      100613  ...   \n",
       "161215    Pediatric Urology        Day   PDSC          1        6259  ...   \n",
       "161216    Pediatric Surgery  Admission     5A          2      105057  ...   \n",
       "161217    Pediatric Surgery  Admission     5A          2      105057  ...   \n",
       "161218    Pediatric Surgery  Admission     5A          1      105057  ...   \n",
       "\n",
       "       condition source value surgery room previous surgery emergency status  \\\n",
       "0                   D00002196          203                N                N   \n",
       "1                   D00003798          504                N                N   \n",
       "2                   D00003798          504                Y                N   \n",
       "3                   D00003798          504                Y                N   \n",
       "4                   D00018711          108                N                N   \n",
       "...                       ...          ...              ...              ...   \n",
       "161214              D00011688            5                N                Y   \n",
       "161215              D00016707            7                N                N   \n",
       "161216              D00011524            5                N                N   \n",
       "161217              D00004831            5                N                N   \n",
       "161218              D00011589            5                N                N   \n",
       "\n",
       "       op timing day of the week week of the month      month  \\\n",
       "0            TF2        Thursday                 4    October   \n",
       "1             8A          Friday                 2    January   \n",
       "2            TF4          Monday                 4      April   \n",
       "3            TF2          Monday                 3     August   \n",
       "4            TF4          Monday                 5      March   \n",
       "...          ...             ...               ...        ...   \n",
       "161214       etc         Tuesday                 2  September   \n",
       "161215        8A          Monday                 4  September   \n",
       "161216        8A       Wednesday                 3  September   \n",
       "161217       TF6       Wednesday                 3  September   \n",
       "161218        8A          Friday                 4  September   \n",
       "\n",
       "       surgeon estimated op time surgery duration  \n",
       "0                            130               66  \n",
       "1                            300              130  \n",
       "2                            100               85  \n",
       "3                            100               83  \n",
       "4                            100               63  \n",
       "...                          ...              ...  \n",
       "161214                       200              123  \n",
       "161215                       130               45  \n",
       "161216                       130               43  \n",
       "161217                       130               82  \n",
       "161218                       130               75  \n",
       "\n",
       "[161219 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 현재 파이썬 코드의 파일 경로\n",
    "current_path = os.getcwd()  # 현재 작업 디렉토리를 가져옵니다.\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = os.path.join(current_path, 'filtered_data.csv')  # User uploaded fioytle to this path\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61344     122\n",
       "137241     48\n",
       "139478     76\n",
       "113549     36\n",
       "149411    127\n",
       "         ... \n",
       "119879     76\n",
       "103694     57\n",
       "131932    311\n",
       "146867     82\n",
       "121958     57\n",
       "Name: surgery duration, Length: 128975, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Removing unnecessary columns\n",
    "df.drop(columns=['note id', 'person id', 'surgeon estimated op time', 'final op name'], inplace=True)\n",
    "\n",
    "# Encoding binary columns\n",
    "binary_cols = ['condition source value', 'op code', 'surgeon id', 'ward', 'admission department', 'surgery room']\n",
    "for col in binary_cols:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "# One-hot encoding for other categorical columns\n",
    "one_hot_cols = ['surgical department', 'op timing', 'month', 'anesthesia type', \n",
    "                'day of the week', 'asa class', 'week of the month', \n",
    "                'division', 'previous surgery', 'emergency status', 'gender source value']\n",
    "df_encoded = pd.get_dummies(df, columns=one_hot_cols)\n",
    "\n",
    "# Splitting the data\n",
    "X_all = df_encoded.drop(\"surgery duration\", axis=1)\n",
    "y_all = df_encoded[\"surgery duration\"]\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the first few rows of the resulting dataframe\n",
    "X_train_all\n",
    "y_train_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 16.67870301451433, RMSE: 31.662393537060968, R²: 0.9158268414503081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련 (랜덤 포레스트 예시)\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_rf = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_rf = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_rf}, RMSE: {rmse_rf}, R²: {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 50.2211215236737, RMSE: 76.9795817900624, R²: 0.5024494234514032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_lr = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_lr = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_lr}, RMSE: {rmse_lr}, R²: {r2_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 22.601232791322957, RMSE: 37.310003900594154, R²: 0.883120935189753\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = XGBRegressor(random_state=42)\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_xgb = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_xgb = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_xgb}, RMSE: {rmse_xgb}, R²: {r2_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble MAE: 8.789387172807343, RMSE: 33.36653615556264, R²: 0.9065222205584245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_dt = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_dt = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_dt}, RMSE: {rmse_dt}, R²: {r2_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할 및 정규화\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_dept = scaler.fit_transform(X_train_dept)\n",
    "    X_test_dept = scaler.transform(X_test_dept)\n",
    "\n",
    "    # 신경망 모델 구성\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train_dept.shape[1],)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train_dept, y_train_dept, epochs=10, batch_size=32, verbose=0)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept).flatten()\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "    X_test_all_scaled = scaler.transform(X_test_all.loc[dept_indices])\n",
    "    dept_predictions = model.predict(X_test_all_scaled).flatten()\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_dl = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_dl = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_dl = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Deep Learning Ensemble MAE: {mae_dl}, RMSE: {rmse_dl}, R²: {r2_dl}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 29172, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score 156.203071\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 935\n",
      "[LightGBM] [Info] Number of data points in the train set: 9417, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 138.766380\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 13293, number of used features: 64\n",
      "[LightGBM] [Info] Start training from score 133.600617\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 13949, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 57.941501\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 9208, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 131.215030\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 10192, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 114.860184\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 6768, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 139.017878\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 5749, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 240.737520\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 7472, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 233.097698\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 783\n",
      "[LightGBM] [Info] Number of data points in the train set: 4611, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 84.449360\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 955\n",
      "[LightGBM] [Info] Number of data points in the train set: 3124, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 143.928297\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 595\n",
      "[LightGBM] [Info] Number of data points in the train set: 1500, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 272.156000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 2380, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 112.698319\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 3216, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 97.698694\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 6285, number of used features: 56\n",
      "[LightGBM] [Info] Start training from score 56.602864\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 1699, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 115.839906\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 499\n",
      "[LightGBM] [Info] Number of data points in the train set: 932, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 295.402361\n",
      "Ensemble MAE: 28.908992268322443, RMSE: 46.733625866924136, R²: 0.8166229026907913\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 분과별 데이터셋 준비\n",
    "departments = df['surgical department'].unique()\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 각 분과별 모델 훈련\n",
    "for dept in departments:\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 분과별 데이터 필터링\n",
    "    dept_data = df_encoded[df_encoded[dept_col_name] == 1]\n",
    "    X_dept = dept_data.drop('surgery duration', axis=1)\n",
    "    y_dept = dept_data['surgery duration']\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_dept, X_test_dept, y_train_dept, y_test_dept = train_test_split(X_dept, y_dept, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 훈련\n",
    "    model = LGBMRegressor(random_state=42)\n",
    "    model.fit(X_train_dept, y_train_dept)\n",
    "    models[dept] = model\n",
    "\n",
    "    # 테스트 데이터셋에 대한 예측 수행\n",
    "    predictions[dept] = model.predict(X_test_dept)\n",
    "\n",
    "# 앙상블을 위한 준비\n",
    "final_predictions = np.zeros(len(X_test_all))\n",
    "test_indices = X_test_all.index\n",
    "\n",
    "# 각 분과별 모델을 전체 테스트 데이터셋에 적용\n",
    "for dept, model in models.items():\n",
    "    # 열 이름 조정\n",
    "    dept_col_name = 'surgical department_' + dept\n",
    "\n",
    "    # 해당 분과에 해당하는 테스트 데이터 인덱스\n",
    "    dept_indices = X_test_all[X_test_all[dept_col_name] == 1].index\n",
    "\n",
    "    # 해당 분과의 예측값 계산\n",
    "    dept_predictions = model.predict(X_test_all.loc[dept_indices])\n",
    "\n",
    "    # 최종 예측 배열에 해당 부분 업데이트\n",
    "    final_predictions[np.isin(test_indices, dept_indices)] = dept_predictions\n",
    "\n",
    "# 성능 평가\n",
    "mae_lgbm = mean_absolute_error(y_test_all, final_predictions)\n",
    "rmse_lgbm = np.sqrt(mean_squared_error(y_test_all, final_predictions))\n",
    "r2_lgbm = r2_score(y_test_all, final_predictions)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae_lgbm}, RMSE: {rmse_lgbm}, R²: {r2_lgbm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 7472, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 233.097698\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 29172, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score 156.203071\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 5749, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 240.737520\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 9208, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 131.215030\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 13949, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 57.941501\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 13293, number of used features: 64\n",
      "[LightGBM] [Info] Start training from score 133.600617\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 935\n",
      "[LightGBM] [Info] Number of data points in the train set: 9417, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 138.766380\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 499\n",
      "[LightGBM] [Info] Number of data points in the train set: 932, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 295.402361\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 669\n",
      "[LightGBM] [Info] Number of data points in the train set: 6285, number of used features: 56\n",
      "[LightGBM] [Info] Start training from score 56.602864\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 955\n",
      "[LightGBM] [Info] Number of data points in the train set: 3124, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 143.928297\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 783\n",
      "[LightGBM] [Info] Number of data points in the train set: 4611, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 84.449360\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 601\n",
      "[LightGBM] [Info] Number of data points in the train set: 1699, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 115.839906\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 3216, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 97.698694\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 595\n",
      "[LightGBM] [Info] Number of data points in the train set: 1500, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 272.156000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 2380, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 112.698319\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 6768, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 139.017878\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 10192, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 114.860184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 37.62154149027628,\n",
       " 'XGBoost': 38.86618902617419,\n",
       " 'Linear Regression': 54.28266078623502,\n",
       " 'LightGBM': 37.66210130359778,\n",
       " 'Decision Tree': 49.840933944191285}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# Adding 'surgical_department' back to df_encoded\n",
    "df_encoded['surgical department'] = df['surgical department']\n",
    "\n",
    "# Splitting the data based on 'surgical_department'\n",
    "department_subsets = df_encoded.groupby('surgical department')\n",
    "\n",
    "model_averages = {\n",
    "    \"Random Forest\": [],\n",
    "    \"XGBoost\": [],\n",
    "    \"Linear Regression\": [],\n",
    "    \"LightGBM\": [],\n",
    "    \"Decision Tree\": []\n",
    "}\n",
    "\n",
    "\n",
    "for department, data in department_subsets:\n",
    "    X = data.drop([\"surgery duration\", \"surgical department\"], axis=1)\n",
    "    y = data[\"surgery duration\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(random_state=42),\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"LightGBM\": LGBMRegressor(random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        mae, _, _ = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "        model_averages[name].append(mae)\n",
    "\n",
    "# Calculate the average MAE for each model across all departments\n",
    "average_mae_per_model = {model: np.mean(maes) for model, maes in model_averages.items()}\n",
    "average_mae_per_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surgical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
